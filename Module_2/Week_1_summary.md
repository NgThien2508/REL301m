# Tá»•ng káº¿t Tuáº§n 1: K-Armed Bandits vÃ  CÃ¡c KhÃ¡i niá»‡m CÆ¡ báº£n

## 1. Váº¥n Ä‘á» K-Armed Bandit

### 1.1 Äá»‹nh nghÄ©a
- **K-Armed Bandit** lÃ  má»™t bÃ i toÃ¡n trong há»c tÄƒng cÆ°á»ng (Reinforcement Learning) trong Ä‘Ã³:
  - Agent pháº£i chá»n giá»¯a k hÃ nh Ä‘á»™ng khÃ¡c nhau
  - Má»—i hÃ nh Ä‘á»™ng mang láº¡i pháº§n thÆ°á»Ÿng ngáº«u nhiÃªn
  - Má»¥c tiÃªu lÃ  tá»‘i Ä‘a hÃ³a tá»•ng pháº§n thÆ°á»Ÿng

### 1.2 Cáº¥u trÃºc cÆ¡ báº£n
```
Agent â†’ Chá»n 1 trong k hÃ nh Ä‘á»™ng â†’ Nháº­n pháº§n thÆ°á»Ÿng
VÃ­ dá»¥ vá»›i k = 3:
- HÃ nh Ä‘á»™ng 1: Pháº§n thÆ°á»Ÿng trung bÃ¬nh tháº¥p ğŸ˜Ÿ
- HÃ nh Ä‘á»™ng 2: Pháº§n thÆ°á»Ÿng trung bÃ¬nh trung bÃ¬nh ğŸ˜
- HÃ nh Ä‘á»™ng 3: Pháº§n thÆ°á»Ÿng trung bÃ¬nh cao ğŸ˜Š
```

## 2. GiÃ¡ trá»‹ HÃ nh Ä‘á»™ng (Action Values)

### 2.1 Äá»‹nh nghÄ©a toÃ¡n há»c
- **GiÃ¡ trá»‹ thá»±c cá»§a hÃ nh Ä‘á»™ng** (True Action Value):
  ```
  q*(a) = E[Rt | At = a]  âˆ€a âˆˆ {1,...,k}
  ```
  - q*(a): GiÃ¡ trá»‹ thá»±c cá»§a hÃ nh Ä‘á»™ng a
  - E[Rt]: Ká»³ vá»ng pháº§n thÆ°á»Ÿng táº¡i thá»i Ä‘iá»ƒm t
  - At = a: Khi chá»n hÃ nh Ä‘á»™ng a

### 2.2 Æ¯á»›c lÆ°á»£ng giÃ¡ trá»‹
1. **PhÆ°Æ¡ng phÃ¡p trung bÃ¬nh máº«u (Sample-Average Method)**:
   ```
   Qt(a) = (Tá»•ng pháº§n thÆ°á»Ÿng khi chá»n a) / (Sá»‘ láº§n chá»n a)
         = Î£(Rt) / (t-1)
   ```

2. **Cáº­p nháº­t gia tÄƒng (Incremental Update)**:
   ```
   Qt+1(a) = Qt(a) + 1/Nt(a) * [Rt - Qt(a)]
   ```
   - Qt(a): Æ¯á»›c lÆ°á»£ng hiá»‡n táº¡i
   - Rt: Pháº§n thÆ°á»Ÿng má»›i
   - Nt(a): Sá»‘ láº§n chá»n a
   - [Rt - Qt(a)]: Sai sá»‘

## 3. ThÄƒm dÃ² vÃ  Khai thÃ¡c (Exploration vs. Exploitation)

### 3.1 Äá»‹nh nghÄ©a
- **ThÄƒm dÃ² (Exploration)**: 
  - Cáº£i thiá»‡n kiáº¿n thá»©c cho lá»£i Ã­ch dÃ i háº¡n
  - Thá»­ nghiá»‡m cÃ¡c hÃ nh Ä‘á»™ng má»›i

- **Khai thÃ¡c (Exploitation)**:
  - Sá»­ dá»¥ng kiáº¿n thá»©c hiá»‡n cÃ³ cho lá»£i Ã­ch ngáº¯n háº¡n
  - Chá»n hÃ nh Ä‘á»™ng tá»‘t nháº¥t Ä‘Ã£ biáº¿t

### 3.2 PhÆ°Æ¡ng phÃ¡p Îµ-greedy
```
At â† {
    argmax Qt(a)               vá»›i xÃ¡c suáº¥t 1-Îµ
    a ~ Uniform({a1...ak})     vá»›i xÃ¡c suáº¥t Îµ
}
```
- Îµ: Tá»· lá»‡ thÄƒm dÃ² (thÆ°á»ng 0.1 hoáº·c nhá» hÆ¡n)
- 1-Îµ: Tá»· lá»‡ khai thÃ¡c
- Uniform: Chá»n ngáº«u nhiÃªn Ä‘á»u

## 4. GiÃ¡ trá»‹ Khá»Ÿi táº¡o Láº¡c quan (Optimistic Initial Values)

### 4.1 NguyÃªn lÃ½
- Khá»Ÿi táº¡o Qt(a) vá»›i giÃ¡ trá»‹ cao hÆ¡n q*(a)
- VÃ­ dá»¥: Q1(a) = 2.0 cho má»i a
- Táº¡o Ä‘á»™ng lá»±c thÄƒm dÃ² tá»± nhiÃªn

### 4.2 Æ¯u Ä‘iá»ƒm
- ThÄƒm dÃ² cÃ³ há»‡ thá»‘ng ban Ä‘áº§u
- Tá»± Ä‘á»™ng giáº£m thÄƒm dÃ² theo thá»i gian
- KhÃ´ng cáº§n tham sá»‘ Îµ

## 5. PhÆ°Æ¡ng phÃ¡p UCB (Upper-Confidence Bound)

### 5.1 CÃ´ng thá»©c
```
At = argmax[Qt(a) + c*sqrt(ln t/Nt(a))]
```
- Qt(a): Pháº§n khai thÃ¡c (exploit)
- c*sqrt(ln t/Nt(a)): Pháº§n thÄƒm dÃ² (explore)
- c: Tham sá»‘ kiá»ƒm soÃ¡t má»©c Ä‘á»™ thÄƒm dÃ²

### 5.2 NguyÃªn lÃ½ "Upper-Confidence Bound"
- Tá»± Ä‘á»™ng cÃ¢n báº±ng thÄƒm dÃ² vÃ  khai thÃ¡c
- Æ¯u tiÃªn hÃ nh Ä‘á»™ng Ã­t Ä‘Æ°á»£c thá»­
- Giáº£m thÄƒm dÃ² khi cÃ³ nhiá»u thÃ´ng tin

## 6. Káº¿t luáº­n

K-Armed Bandit lÃ  ná»n táº£ng cho cÃ¡c khÃ¡i niá»‡m quan trá»ng trong há»c tÄƒng cÆ°á»ng:
- CÃ¢n báº±ng thÄƒm dÃ² vÃ  khai thÃ¡c
- Æ¯á»›c lÆ°á»£ng vÃ  cáº­p nháº­t giÃ¡ trá»‹
- Ra quyáº¿t Ä‘á»‹nh trong Ä‘iá»u kiá»‡n khÃ´ng cháº¯c cháº¯n

-------------------------------------------
##### 8-12-2025 at 10PM.
##### Course: Fundamentals of Reinforcement Learning/Module 2.
##### Äá»c tÃ i liá»‡u táº¡i: Week 1 Summary
##### Há»c ná»™i dung tá»« clip: Week 1 Summary
