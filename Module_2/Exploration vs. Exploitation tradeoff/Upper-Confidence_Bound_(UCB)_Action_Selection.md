# Phương pháp UCB (Upper-Confidence Bound) trong việc lựa chọn hành động

## 1. Tổng quan về UCB
Upper-Confidence Bound (UCB) là một phương pháp thông minh để cân bằng giữa thăm dò và khai thác trong học tăng cường, dựa trên độ không chắc chắn trong các ước tính giá trị hành động.

### 1.1 Tại sao cần UCB?
- Cải thiện phương pháp ε-greedy truyền thống
- Sử dụng thông tin về độ không chắc chắn để thăm dò thông minh hơn
- Áp dụng nguyên tắc "lạc quan trong sự không chắc chắn"

## 2. Hiểu về độ không chắc chắn

### 2.1 Khoảng tin cậy là gì?
- $Q(a)$: Giá trị ước tính hiện tại của hành động $a$
- Khoảng tin cậy: Vùng mà giá trị thực $q_*(a)$ có thể nằm trong
- Cận dưới (lower bound) và cận trên (upper bound)
- Độ rộng của khoảng thể hiện mức độ không chắc chắn

### 2.2 Cách hiểu trực quan về độ không chắc chắn
```
Ví dụ khoảng tin cậy:
- Khoảng hẹp: Ước tính đáng tin cậy
  [|----Q(a)----]
  
- Khoảng rộng: Ước tính không chắc chắn
  [|---------Q(a)--------]
```

## 3. Cách UCB chọn hành động

### 3.1 Nguyên tắc cơ bản
- Khi không chắc chắn về giá trị của một hành động
- Giả định lạc quan rằng nó có thể là tốt nhất
- Chọn hành động có cận trên cao nhất

### 3.2 Ví dụ đơn giản
```
Ba hành động với độ không chắc chắn khác nhau:

Q(1): [|-------|]
Q(2):    [|-|]
Q(3):  [|------|]

→ Chọn Q(1) vì có cận trên cao nhất
```

## 4. Cách tính toán trong UCB

### 4.1 Công thức toán học
$$ A_t = \underset{a}{\text{argmax}} \left[Q_t(a) + c\sqrt{\frac{\ln t}{N_t(a)}}\right] $$

Trong đó:
- $Q_t(a)$: Giá trị ước tính của hành động $a$ tại thời điểm $t$
- $c$: Tham số kiểm soát mức độ thăm dò
- $t$: Số bước thời gian đã trải qua
- $N_t(a)$: Số lần hành động $a$ được chọn

### 4.2 Giải thích từng phần của công thức
1. Phần khai thác: $Q_t(a)$
   - Giá trị ước tính hiện tại
   - Khuyến khích chọn hành động có giá trị cao

2. Phần thăm dò: $c\sqrt{\frac{\ln t}{N_t(a)}}$
   - Tăng khi hành động ít được chọn
   - Giảm khi hành động được chọn nhiều lần

### 4.3 Ví dụ với con số thực tế
```
Sau 10,000 bước:

1. Hành động được chọn 5,000 lần:
   c√(ln 10000/5000) ≈ 0.043c

2. Hành động được chọn 100 lần:
   c√(ln 10000/100) ≈ 0.303c
   (độ không chắc chắn cao hơn 10 lần)
```

### 4.4 Ví dụ thực tế: Hệ thống gợi ý nhà hàng

Giả sử bạn đang xây dựng một ứng dụng đề xuất nhà hàng với 3 nhà hàng:
- Nhà hàng A: Phở
- Nhà hàng B: Cơm tấm
- Nhà hàng C: Bún bò

#### Dữ liệu ban đầu (sau 100 lượt đề xuất):
```
Nhà hàng | Số lần chọn (N) | Điểm TB (Q) | Độ không chắc chắn (c√(ln 100/N))
---------|----------------|-------------|--------------------------------
Phở      | 50             | 4.2         | 0.37c
Cơm tấm  | 30             | 4.0         | 0.47c
Bún bò   | 20             | 4.5         | 0.58c

Với c = 2:
UCB(Phở)    = 4.2 + 2(0.37) = 4.94
UCB(Cơm tấm) = 4.0 + 2(0.47) = 4.94
UCB(Bún bò)  = 4.5 + 2(0.58) = 5.66
```

#### Phân tích quyết định:
1. **Điểm trung bình (Q)**:
   - Bún bò có điểm cao nhất (4.5)
   - Phở đứng thứ hai (4.2)
   - Cơm tấm thấp nhất (4.0)

2. **Độ không chắc chắn**:
   - Bún bò: Cao nhất (0.58c) vì ít được chọn nhất
   - Cơm tấm: Trung bình (0.47c)
   - Phở: Thấp nhất (0.37c) vì được chọn nhiều nhất

3. **Quyết định UCB**:
   - Chọn Bún bò vì có UCB cao nhất (5.66)
   - Kết hợp cả điểm cao và độ không chắc chắn cao

#### Diễn biến theo thời gian:

1. **Lượt tiếp theo**:
   ```
   Giả sử khách cho Bún bò 4.0 sao:
   - N(Bún bò) tăng lên 21
   - Q(Bún bò) giảm xuống: 4.48
   - Độ không chắc chắn giảm
   - UCB của Bún bò sẽ giảm
   ```

2. **Sau nhiều lượt**:
   ```
   Khi t = 1000:
   - Độ không chắc chắn giảm với mọi nhà hàng
   - UCB gần với điểm thực tế hơn
   - Hệ thống tập trung vào nhà hàng có điểm cao nhất
   ```

#### Ưu điểm của UCB trong ví dụ này:
1. **Thăm dò thông minh**:
   - Tự động thử nhà hàng ít được chọn
   - Không bỏ qua nhà hàng có tiềm năng

2. **Cân bằng tự nhiên**:
   - Không cần đặt tỷ lệ thăm dò cố định
   - Tự điều chỉnh dựa trên dữ liệu

3. **Công bằng với nhà hàng mới**:
   - Nhà hàng ít được chọn có cơ hội được thử
   - Tránh thiên vị với nhà hàng phổ biến

## 5. So sánh UCB với phương pháp ε-greedy

### 5.1 Cách thức thử nghiệm
- Môi trường: 10-armed Testbed
- UCB: c = 2
- ε-greedy: ε = 0.1
- 2,000 lần chạy độc lập

### 5.2 Kết quả so sánh
1. **Giai đoạn đầu (0-100 lượt)**:
   - UCB thăm dò nhiều hơn
   - Phần thưởng trung bình thấp hơn

2. **Giai đoạn sau (>100 lượt)**:
   - UCB đạt hiệu suất cao hơn
   - Thăm dò giảm dần theo thời gian
   - ε-greedy vẫn duy trì 10% thăm dò

### 5.3 Điểm mạnh của UCB
1. Thăm dò thông minh hơn:
   - Tập trung vào hành động chưa chắc chắn
   - Giảm dần thăm dò khi có đủ thông tin

2. Hiệu suất dài hạn tốt hơn:
   - Đạt phần thưởng trung bình cao hơn
   - Cân bằng tốt giữa thăm dò và khai thác

## 6. Tóm tắt những điểm chính

UCB giúp:
- Sử dụng thông tin về độ không chắc chắn một cách hiệu quả
- Thăm dò có hệ thống và thông minh
- Tự động điều chỉnh mức độ thăm dò
- Đạt kết quả tốt hơn so với ε-greedy

----------------------------------------------------------------------------------------------------------------------------                                                                                                                                    
##### 8-12-2025 at 7PM.
##### Course: Fundamentals of Reinforcement Learning/Module 2.
##### Đọc tài liệu tại: Exploration vs. Exploitation tradeoff
##### Học nội dung từ clip: Exploration vs. Exploitation tradeoff/Upper-Confidence Bound (UCB) Action Selection.
